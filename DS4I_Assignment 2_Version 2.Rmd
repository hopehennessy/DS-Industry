---
title: "Ensemble Recommender System for Book Recommendations: A Comparative Analysis of Collaborative Filtering Approaches"
author: "Hope Hennessy"
date: "2025-10-01"
output: pdf_document
---

\newpage

# Abstract

This study presents a comprehensive comparative analysis of four collaborative filtering approaches for book recommendation systems using a modified Book-Crossing dataset. We implement item-based collaborative filtering, user-based collaborative filtering, matrix factorization, and neural network-based methods to build an ensemble recommender system. Our analysis includes cross-validation performance evaluation, cold start problem handling, and investigation of dataset size effects on predictive accuracy. The results demonstrate the relative strengths and limitations of each approach, providing insights for practical recommendation system deployment.

## Assignment Overview

Build an ensemble recommender system for book recommendations using a modified "Book-Crossing" dataset containing ratings (0-10 scale) from 10,000 users on 150 books.

### Core Requirements

1. **Build Four Types of Recommender Systems:**
   - Item-based collaborative filtering (code from scratch)
   - User-based collaborative filtering (code from scratch)
   - Matrix factorization-based collaborative filtering
   - Neural network-based collaborative filtering

2. **System Capabilities:**
   - Recommend books to existing users
   - Handle new users (assuming they provide ratings for ≤5 books initially)

3. **Evaluation and Analysis:**
   - Compare accuracy across all four methods using cross-validation
   - Investigate the relationship between dataset size and accuracy
   - Determine if there's a point where adding more titles doesn't improve accuracy

4. **Data Analysis:**
   - Conduct exploratory data analysis (EDA)
   - Use findings to inform train/test data splitting

# 1. Introduction

## 1.1 Background

Recommender systems have become essential components of modern digital platforms, helping users discover relevant content from vast catalogs. Collaborative filtering approaches, which leverage user-item interaction patterns, remain among the most effective recommendation techniques. This study focuses on book recommendation systems, which face unique challenges including high sparsity, diverse user preferences, and the cold start problem for new users.

## 1.2 Objectives

The primary objectives of this research are:

1. **Implement Four Collaborative Filtering Methods**: Develop item-based, user-based, matrix factorization, and neural network-based recommendation systems
2. **Comparative Performance Analysis**: Evaluate and compare the accuracy of each method using cross-validation
3. **Cold Start Problem Investigation**: Develop strategies for handling new users with limited rating history
4. **Dataset Size Impact Analysis**: Examine how the number of available titles affects predictive accuracy
5. **Ensemble System Development**: Create a unified recommendation framework combining multiple approaches

# 2. Setup and Data Loading

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE, 
  fig.width = 8, 
  fig.height = 6, 
  fig.align = "center", 
  warning = FALSE, 
  message = FALSE, 
  fig.show = 'hold', 
  out.width = '70%',
  dpi = 300
)

set.seed(123)

# Load required libraries
library(tidyverse)
library(patchwork)
library(caret)
library(kableExtra)
library(recosystem)
library(h2o)
library(dplyr)
library(tidyr)
library(knitr)
library(ggplot2)

# Relax linting rules for academic work
options(lintr.linter_file = "none")  # Disable linting entirely
options(lintr.exclude_linters = c("object_usage_linter", "object_name_linter", 
                                  "cyclocomp_linter", "line_length_linter"))

# ================================================================
# DEDICATED METRIC FUNCTIONS - IMPROVED CODE QUALITY
# ================================================================

# Root Mean Square Error calculation
calculate_rmse <- function(predictions, actual) {
  sqrt(mean((predictions - actual)^2, na.rm = TRUE))
}

# Combined evaluation function for convenience
evaluate_predictions <- function(predictions, actual) {
  list(
    rmse = calculate_rmse(predictions, actual)
  )
}
```

## 2.1 Data Loading and Initial Exploration

```{r data-loading}
load("book_ratings.Rdata")

# Data structure
head(book_info)
str(book_info)
dim(book_info)
head(book_ratings)
str(book_ratings)
dim(book_ratings)
head(user_info) # don't need Age to build recommender, but can include this info if want to go further
str(user_info)
dim(user_info)

# Check for missing values
missing_values <- data.frame(
  Dataset = c("Book Info", "Book Ratings", "User Info"),
  Missing_Values = c(
    sum(is.na(book_info)),
    sum(is.na(book_ratings)),
    sum(is.na(user_info))  # 12098 missing Age values
  )
)

```

## 2.2 Data Integration and Quality Assessment

```{r data-merging}
# Merging book_ratings with book_info 
data <- book_ratings %>%
  left_join(book_info, by = "ISBN")

summary(data) # can clearly see age has some impossible outliers
head(data)
dim(data)

sapply(data, function(x) if(is.numeric(x)) range(x, na.rm = TRUE)) # check var ranges

# Check rating distribution
table(data$Book.Rating)

length(unique(data$User.ID))
length(data$User.ID)
```

## 1.3 User Activity Analysis

```{r user-activity-preliminary}
# Group and count the number of records per User.ID
hist_data <- data %>%
  group_by(User.ID) %>%
  count(name = "count")
hist_data

# Check the maximum count
max(hist_data$count)

```


## 1.4 Demographic Data Integration

```{r age-analysis}
# Merge with user_info to include age 
full_data <- data %>%
  left_join(user_info, by = "User.ID")

boxplot(full_data$Age) # Age has some very large outliers
full_data <- full_data %>% filter(full_data$Age < 110) 
# data %>% filter(Age < 5)
```


# 2. Exploratory Data Analysis

## 2.1 Dataset Characteristics

```{r data-summary}
# Basic summary statistics
data_summary <- data.frame(
  Metric = c("Total Users", "Total Books", "Total Ratings", 
             "Average Rating", "Rating Range"),
  Value = c(
    length(unique(data$User.ID)),
    length(unique(data$ISBN)),
    nrow(data),
    round(mean(data$Book.Rating, na.rm = TRUE), 2),
    paste(min(data$Book.Rating, na.rm = TRUE), "-", max(data$Book.Rating, na.rm = TRUE))
  )
)

kable(data_summary, caption = "Dataset Summary") %>%
  kable_styling(latex_options = "HOLD_position")

# Rating distribution
rating_dist <- table(data$Book.Rating)
rating_dist_df <- data.frame(
  Rating = names(rating_dist),
  Count = as.numeric(rating_dist),
  Percentage = round(as.numeric(rating_dist) / sum(rating_dist) * 100, 1)
)

kable(rating_dist_df, caption = "Rating Distribution") %>%
  kable_styling(latex_options = "HOLD_position")

# Rating histogram
hist(data$Book.Rating, main = "Distribution of Book Ratings",
     col = "steelblue", xlab = "Rating", ylab = "Frequency")

# ================================================================
# USER AND BOOK ACTIVITY ANALYSIS
# ================================================================

# User activity analysis
user_activity <- data %>%
  group_by(User.ID) %>%
  summarise(
    num_ratings = n(),
    avg_rating = mean(Book.Rating, na.rm = TRUE),
    .groups = "drop"
  )

# Book popularity analysis
book_popularity <- data %>%
  group_by(ISBN) %>%
  summarise(
    num_ratings = n(),
    avg_rating = mean(Book.Rating, na.rm = TRUE),
    .groups = "drop"
  )

# User activity summary table
user_activity_summary <- data.frame(
  Metric = c(
    "Total Users",
    "Min Ratings per User", 
    "Max Ratings per User",
    "Mean Ratings per User",
    "Users with 1-2 Ratings",
    "Users with 3-5 Ratings", 
    "Users with 6-10 Ratings",
    "Users with 11-20 Ratings",
    "Users with >20 Ratings"
  ),
  Value = c(
    nrow(user_activity),
    min(user_activity$num_ratings),
    max(user_activity$num_ratings),
    round(mean(user_activity$num_ratings), 2),
    sum(user_activity$num_ratings <= 2),
    sum(user_activity$num_ratings >= 3 & user_activity$num_ratings <= 5),
    sum(user_activity$num_ratings >= 6 & user_activity$num_ratings <= 10),
    sum(user_activity$num_ratings >= 11 & user_activity$num_ratings <= 20),
    sum(user_activity$num_ratings > 20)
  )
)

kable(user_activity_summary, caption = "User Activity Distribution") %>%
  kable_styling(latex_options = "HOLD_position")

# Book popularity summary table
book_popularity_summary <- data.frame(
  Metric = c(
    "Total Books",
    "Min Ratings per Book",
    "Max Ratings per Book", 
    "Mean Ratings per Book",
    "Books with 1-4 Ratings",
    "Books with 5-9 Ratings",
    "Books with 10-19 Ratings", 
    "Books with 20-49 Ratings",
    "Books with ≥50 Ratings"
  ),
  Value = c(
    nrow(book_popularity),
    min(book_popularity$num_ratings),
    max(book_popularity$num_ratings),
    round(mean(book_popularity$num_ratings), 2),
    sum(book_popularity$num_ratings <= 4),
    sum(book_popularity$num_ratings >= 5 & book_popularity$num_ratings <= 9),
    sum(book_popularity$num_ratings >= 10 & book_popularity$num_ratings <= 19),
    sum(book_popularity$num_ratings >= 20 & book_popularity$num_ratings <= 49),
    sum(book_popularity$num_ratings >= 50)
  )
)

kable(book_popularity_summary, caption = "Book Popularity Distribution") %>%
  kable_styling(latex_options = "HOLD_position")

# Dataset sparsity analysis
total_possible_ratings <- length(unique(data$User.ID)) * length(unique(data$ISBN))
actual_ratings <- nrow(data)
sparsity_percentage <- round((1 - actual_ratings / total_possible_ratings) * 100, 2)

sparsity_summary <- data.frame(
  Metric = c(
    "Total Possible User-Book Pairs",
    "Actual Ratings",
    "Sparsity Percentage",
    "Data Density"
  ),
  Value = c(
    format(total_possible_ratings, big.mark = ","),
    format(actual_ratings, big.mark = ","),
    paste0(sparsity_percentage, "%"),
    paste0(round(100 - sparsity_percentage, 2), "%")
  )
)

kable(sparsity_summary, caption = "Dataset Sparsity Analysis") %>%
  kable_styling(latex_options = "HOLD_position")
```



## 2.2 Sample Data for Experimental Validation

```{r sample-data}
set.seed(123)
sample_users <- sample(unique(book_ratings$User.ID), 4000)
sample_data <- data %>% filter(User.ID %in% sample_users)

cat("Sample data dimensions:", dim(sample_data), "\n")
cat("Sample users:", length(unique(sample_data$User.ID)), "\n")
cat("Sample books:", length(unique(sample_data$ISBN)), "\n")
```


```{r matrix-construction}
# -------------------------------------------------------------------
# Count ratings per book
# -------------------------------------------------------------------
counts_per_book <- data %>%
  group_by(ISBN) %>%
  summarise(num_ratings = n(), .groups = "drop")

# Plot distribution
ggplot(counts_per_book, aes(x = num_ratings)) +
  geom_histogram(binwidth = 1, fill = "skyblue", color = "black") +
  scale_x_continuous(limits = c(0, quantile(counts_per_book$num_ratings, 0.95))) +
  labs(title = "Distribution of Ratings per Book",
       x = "Number of Ratings",
       y = "Count of Books")


# -------------------------------------------------------------------
# Count ratings per user
# -------------------------------------------------------------------
counts_per_user <- data %>%
  group_by(User.ID) %>%
  summarise(num_ratings = n(), .groups = "drop")

users_per_count <- counts_per_user %>%
  count(num_ratings, name = "num_users")

# Plot distribution
ggplot(counts_per_user, aes(x = num_ratings)) +
  geom_histogram(binwidth = 1, fill = "lightgreen", color = "black") +
  scale_x_continuous(limits = c(0, quantile(counts_per_user$num_ratings, 0.95))) +
  labs(title = "Distribution of Ratings per User",
       x = "Number of Ratings",
       y = "Count of Users")

# Total unique users
length(unique(data$User.ID))
```


# 3. User-Item Matrix Construction

```{r unified-matrix-creation}

# User-item matrix creation function
create_user_item_matrix <- function(ratings_data, min_ratings_per_book = 3, 
                                    min_ratings_per_user = 2) {
  
  # Convert 0 ratings to NA (unrated)
  ratings_clean <- ratings_data %>%
    mutate(Book.Rating = ifelse(Book.Rating == 0, NA, Book.Rating))
  
  # Convert to wide format
  user_item_matrix <- ratings_clean %>%
    select(User.ID, ISBN, Book.Rating) %>%
    pivot_wider(names_from = ISBN, values_from = Book.Rating, values_fill = NA)
  
  # Convert to matrix
  user_ids <- user_item_matrix$User.ID
  user_item_matrix <- as.matrix(user_item_matrix[, -1])
  rownames(user_item_matrix) <- user_ids
  
  # Filter books with too few ratings
  books_to_keep <- colSums(!is.na(user_item_matrix)) >= min_ratings_per_book
  user_item_matrix <- user_item_matrix[, books_to_keep]
  
  # Filter users with too few ratings
  users_to_keep <- rowSums(!is.na(user_item_matrix)) >= min_ratings_per_user
  user_item_matrix <- user_item_matrix[users_to_keep, ]
  
  return(user_item_matrix)
}

```

```{r}
# Evaluation metrics function
evaluate_predictions <- function(predictions, actual) {
  valid_idx <- !is.na(predictions) & !is.na(actual)
 
  rmse <- sqrt(mean((predictions[valid_idx] - actual[valid_idx])^2))
  
  return(list(rmse = rmse))
}

```


# 4. Collaborative Filtering Methods Implementation

## 4.1 User-Based Collaborative Filtering (UBCF)


```{r ubcf-functions}

# User-mean normalization function
normalize_matrix_user <- function(user_item_matrix) {
  
  # Center ratings by subtracting user mean
  user_means <- rowMeans(user_item_matrix, na.rm = TRUE)
  user_item_matrix_normalized <- sweep(user_item_matrix, 1, user_means, FUN = "-")
  
  return(list(normalized = user_item_matrix_normalized, means = user_means))
}


# Cosine similarity matrix computation for users
compute_user_similarity_matrix <- function(user_item_matrix_normalized) {
  
  n_users <- nrow(user_item_matrix_normalized)
  
  # Replace NA with 0 for matrix operations
  mat <- user_item_matrix_normalized
  mat[is.na(mat)] <- 0
  
  # Dot products between user rating vectors (numerator)
  numerator <- mat %*% t(mat)
  
  # Magnitudes (denominator)
  magnitudes <- sqrt(rowSums(mat^2))
  denominator <- outer(magnitudes, magnitudes)
  
  # Cosine similarity calculation
  user_similarity_matrix <- numerator / denominator
  
  # Replace NaN values with 0
  user_similarity_matrix[is.nan(user_similarity_matrix)] <- 0
  
  # Set self-similarity to 0
  diag(user_similarity_matrix) <- 0

  rownames(user_similarity_matrix) <- rownames(user_item_matrix_normalized)
  colnames(user_similarity_matrix) <- rownames(user_item_matrix_normalized)
  
  return(user_similarity_matrix)
}
```

```{r ubcf-recommendation-functions}
# Recommendation function for existing users (UBCF)
recommend_for_user_ubcf <- function(target_user, user_item_matrix, 
                                    user_item_matrix_normalized, user_sim_matrix,
                                    user_means, book_info, n_recommendations = 10, 
                                    k = NULL) {
  
  target_user <- as.character(target_user)
  
  # Get unrated books for target user
  unrated_books <- colnames(user_item_matrix)[is.na(user_item_matrix[target_user, ])]
  
  # Get user similarities
  sims <- user_sim_matrix[target_user, ]
  
  # Replace NA and NaN with 0
  sims[is.na(sims) | is.nan(sims)] <- 0  
  
  # k-NN filtering – keeps only top k most similar users
  if (!is.null(k) && k < length(sims)) {
    non_zero_count <- sum(sims != 0)
    if (non_zero_count > 0) {  # safety check
      k_actual <- min(k, non_zero_count)
      top_k_users <- names(sort(sims, decreasing = TRUE)[1:k_actual])
      sims_filtered <- rep(0, length(sims))
      names(sims_filtered) <- names(sims)
      sims_filtered[top_k_users] <- sims[top_k_users]
      sims <- sims_filtered
    }
  }
  
  # Safety check: Check if any similar users exist - if not return empty df
  if (sum(abs(sims) > 0) == 0) {
    return(data.frame())
  }
  
  # Prepare matrix for prediction
  # Replace NA's with 0's - matrix operations
  mat <- user_item_matrix_normalized
  mat[is.na(mat)] <- 0
  
  # Predicting ratings for unrated books 
  # Taking a similarity-weighted average of ratings from similar users
  weighted_ratings <- t(mat[, unrated_books, drop = FALSE]) %*% sims
  
  # Which users rated each unrated book - boolean matrix
  rated_mask <- !is.na(user_item_matrix[, unrated_books, drop = FALSE])
  
  # Sum of similarities only across users who rated the book
  # Only those with non-zero similarity contribute to the denominator
  sum_sims <- colSums(rated_mask * abs(sims))
  
  # If no similar user rated a book - avoid division by zero
  sum_sims[sum_sims == 0] <- 1
  
  # Calculate predictions (normalized to denormalised)
  preds <- weighted_ratings / sum_sims
  preds[is.nan(preds)] <- NA
  preds <- preds + user_means[target_user]
  
  # Convert matrix to named vector
  preds <- as.vector(preds)
  names(preds) <- unrated_books  
  
  # Clip to valid rating range [1, 10]
  preds <- pmin(pmax(preds, 1), 10)
  
  # Get top N recommendations
  preds_valid <- preds[!is.na(preds)]
  
  if (length(preds_valid) == 0) {return(data.frame())}
  
  top_books <- sort(preds_valid, decreasing = TRUE)[1:min(n_recommendations, length(preds_valid))]
  
  # Df of recommended books & their predicted ratings
  recommendations <- data.frame(
    ISBN = names(top_books),
    Predicted_Rating = as.numeric(top_books)) %>%
    left_join(book_info, by = "ISBN") %>%
    select(ISBN, Book.Title, Book.Author, Predicted_Rating)
  
  return(recommendations)
}
```

```{r}
# Recommendation function for new users (cold start - UBCF)
recommend_for_new_user_ubcf <- function(new_user_ratings, user_item_matrix, 
                                        user_item_matrix_normalized, user_means,
                                        book_info, n_recommendations = 10, 
                                        k = NULL) {
  
  # Input validation
  if (length(new_user_ratings) == 0) {
    return(data.frame())
  }
  
  # New user vector aligned with the training matrix, filled with NA
  new_user_vector <- rep(NA, ncol(user_item_matrix))
  names(new_user_vector) <- colnames(user_item_matrix)
  
  # Fill in the ratings for the user (vectorized approach)
  matched_books <- names(new_user_ratings)[names(new_user_ratings) %in% names(new_user_vector)]
  if (length(matched_books) == 0) {
    return(data.frame())
  }
  new_user_vector[matched_books] <- new_user_ratings[matched_books]
  
  # User-mean normalisation
  new_user_mean <- mean(new_user_vector, na.rm = TRUE)
  new_user_normalized <- new_user_vector - new_user_mean
  new_user_vec <- new_user_normalized
  new_user_vec[is.na(new_user_vec)] <- 0
  
  mat <- user_item_matrix_normalized
  mat[is.na(mat)] <- 0
  
  # Cosine similarity with zero-magnitude check
  existing_magnitudes <- sqrt(rowSums(mat^2))
  new_user_magnitude <- sqrt(sum(new_user_vec^2))
  
  # Check for zero magnitude (cannot compute similarity)
  if (new_user_magnitude == 0) {
    return(data.frame())
  }
  
  new_user_sims <- as.numeric((mat %*% new_user_vec) / (existing_magnitudes * new_user_magnitude))
  new_user_sims[is.nan(new_user_sims)] <- 0
  new_user_sims[is.infinite(new_user_sims)] <- 0
  new_user_sims[is.na(new_user_sims)] <- 0
  names(new_user_sims) <- rownames(user_item_matrix_normalized)
  
  # k-NN filtering
  if (!is.null(k) && k < length(new_user_sims)) {
    top_k_users <- names(sort(new_user_sims, decreasing = TRUE)[1:min(k, sum(new_user_sims != 0))])
    sims_filtered <- rep(0, length(new_user_sims))
    names(sims_filtered) <- names(new_user_sims)
    sims_filtered[top_k_users] <- new_user_sims[top_k_users]
    new_user_sims <- sims_filtered
  }
  
  # No user similarity - empty df
  if (sum(abs(new_user_sims) > 0) == 0) {return(data.frame())}
  
  # Get unrated books
  unrated_books <- names(new_user_vector)[is.na(new_user_vector)]
  
  # If user has rated all the books - empty df
  if (length(unrated_books) == 0) {return(data.frame())}
  
  # Prediction for all unrated books
  weighted_ratings <- t(mat[, unrated_books, drop = FALSE]) %*% new_user_sims
  rated_mask <- !is.na(user_item_matrix[, unrated_books, drop = FALSE])
  sum_sims <- colSums(rated_mask * abs(new_user_sims))

  sum_sims[sum_sims == 0] <- 1
  
  # Calculate predictions (normalised to denormalised)
  preds <- weighted_ratings / sum_sims
  preds[is.nan(preds)] <- NA
  preds <- preds + new_user_mean
  
  # Convert matrix to named vector
  preds <- as.vector(preds)
  names(preds) <- unrated_books 
  
  # Clip to valid rating range [1, 10]
  preds <- pmin(pmax(preds, 1), 10)
  
  # Top N recommendations
  preds_valid <- preds[!is.na(preds)]
  if (length(preds_valid) == 0) {return(data.frame())}
  
  top_books <- sort(preds_valid, decreasing = TRUE)[1:min(n_recommendations, length(preds_valid))]
  
  recommendations <- data.frame(
    ISBN = names(top_books),
    Predicted_Rating = as.numeric(top_books)) %>%
    left_join(book_info, by = "ISBN") %>%
    select(ISBN, Book.Title, Book.Author, Predicted_Rating)
  
  return(recommendations)
}
```


```{r ubcf-implementation}
# ================================================================
# UBCF IMPLEMENTATION
# ================================================================

# Create user-item matrix
user_item_matrix_ubcf <- create_user_item_matrix(
  data, 
  min_ratings_per_book = 5, 
  min_ratings_per_user = 2)

# Normalize matrix (user-mean)
normalized_result_ubcf <- normalize_matrix_user(user_item_matrix_ubcf)
user_item_matrix_normalized_ubcf <- normalized_result_ubcf$normalized
user_means <- normalized_result_ubcf$means

# Compute user similarity matrix
user_similarity_matrix <- compute_user_similarity_matrix(user_item_matrix_normalized_ubcf)

# Recommendations for existing user
sample_user <- rownames(user_item_matrix_ubcf)[3]

recs_ubcf <- recommend_for_user_ubcf(
  target_user = sample_user,
  user_item_matrix = user_item_matrix_ubcf,
  user_item_matrix_normalized = user_item_matrix_normalized_ubcf,
  user_sim_matrix = user_similarity_matrix,
  user_means = user_means,
  book_info = book_info,
  n_recommendations = 10,
  k = 50)  

recs_ubcf %>%
  mutate(Rank = row_number()) %>%
  select(Rank, Book.Title, Book.Author, Predicted_Rating) %>%
  kable(caption = "Top 10 Recommendations for Existing User (UBCF)", 
        digits = 2, align = c("c", "l", "l", "c")) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), 
                full_width = FALSE)

# Recommendations for new user (cold start)
sample_books <- colnames(user_item_matrix_ubcf)[1:5]
new_user_ratings <- setNames(c(8, 9, 7, 6, 8), sample_books)

# Display new user's ratings
new_user_ratings_df <- data.frame(
  ISBN = names(new_user_ratings),
  Rating = as.numeric(new_user_ratings)) %>%
  left_join(book_info, by = "ISBN") %>%
  select(Book.Title, Book.Author, Rating)

new_user_ratings_df %>%
  kable(caption = "New User's Initial Ratings", 
        digits = 0, align = c("l", "l", "c")) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), 
                full_width = FALSE)

new_user_recs_ubcf <- recommend_for_new_user_ubcf(
  new_user_ratings = new_user_ratings,
  user_item_matrix = user_item_matrix_ubcf,
  user_item_matrix_normalized = user_item_matrix_normalized_ubcf,
  user_means = user_means,
  book_info = book_info,
  n_recommendations = 10,
  k = 50)  

new_user_recs_ubcf %>%
  mutate(Rank = row_number()) %>%
  select(Rank, Book.Title, Book.Author, Predicted_Rating) %>%
  kable(caption = "Top 10 Recommendations for New User (UBCF)", 
        digits = 2, align = c("c", "l", "l", "c")) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), 
                full_width = FALSE)
```


```{r cross-validation-ubcf}
# =====================================
# CROSS-VALIDATION FOR USER-BASED CF 
# =====================================

cross_validate_ubcf <- function(user_item_matrix, n_folds = 5, k = 30) {
  
  set.seed(123)
  
  # Get observed ratings
  observed <- which(!is.na(user_item_matrix), arr.ind = TRUE)
  n_ratings <- nrow(observed)
  
  # Create folds
  fold_indices <- sample(rep(1:n_folds, length.out = n_ratings))
  
  # Pre-allocate results dataframe
  cv_results <- data.frame(
    fold = integer(n_folds),
    rmse = numeric(n_folds))
  

  for (fold in 1:n_folds) {
    cat("Fold", fold, "of", n_folds, "... ")
    
    # Split data
    test_indices <- which(fold_indices == fold)
    test_obs <- observed[test_indices, , drop = FALSE]
    
    # Create train matrix
    train_matrix <- user_item_matrix
    train_matrix[test_obs] <- NA
    
    # Normalize (user-mean)
    norm_result <- normalize_matrix_user(train_matrix)
    train_normalized <- norm_result$normalized
    user_means <- norm_result$means
    
    # Compute user similarity
    user_sim_matrix <- compute_user_similarity_matrix(train_normalized)
    
    # Prepare normalized matrix for prediction
    train_norm_filled <- train_normalized
    train_norm_filled[is.na(train_norm_filled)] <- 0
    
    # Make predictions for test set
    predictions <- numeric(nrow(test_obs))
    
    for (i in 1:nrow(test_obs)) {
      user_idx <- test_obs[i, 1]
      item_idx <- test_obs[i, 2]
      
      # Get similarities to all other users
      sims <- user_sim_matrix[user_idx, ]
      sims[is.na(sims) | is.nan(sims)] <- 0
      
      # Apply k-NN filtering
      if (k < length(sims) && sum(abs(sims) > 0) > 0) {
        k_actual <- min(k, sum(abs(sims) > 0))
        top_k_idx <- order(abs(sims), decreasing = TRUE)[1:k_actual]
        sims_filtered <- rep(0, length(sims))
        sims_filtered[top_k_idx] <- sims[top_k_idx]
        sims <- sims_filtered
      }
      
      # Find which users (among similar ones) rated this item
      rated_mask <- !is.na(train_matrix[, item_idx])
      
      # If no similar user rated this item, use user mean
      if (sum(abs(sims[rated_mask])) == 0) {
        predictions[i] <- user_means[user_idx]
        next
      }
      
      # Weighted average of similar users' ratings for this item
      weighted_sum <- sum(sims[rated_mask] * train_norm_filled[rated_mask, item_idx])
      sum_sims <- sum(abs(sims[rated_mask]))
      
      predictions[i] <- (weighted_sum / sum_sims) + user_means[user_idx]
    }
    
    # Clip to valid range
    predictions <- pmin(pmax(predictions, 1), 10)
    
    # Get actual ratings
    actual <- user_item_matrix[test_obs]
    
    # Calculate metrics
    metrics <- evaluate_predictions(predictions, actual)
    
    cv_results[fold, ] <- list(fold, metrics$rmse)
    
  }
  
  return(cv_results)
}

# Run cross-validation
cv_results_ubcf <- cross_validate_ubcf(
  user_item_matrix_ubcf, 
  n_folds = 5, 
  k = 50)

# Display results
cv_results_ubcf %>%
  kable(caption = "UBCF Cross-Validation Results", 
        digits = 4, 
        col.names = c("Fold", "RMSE"),
        align = c("c", "c")) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), 
                full_width = FALSE)
```




## 4.2 Item-Based Collaborative Filtering (IBCF)

Item-based collaborative filtering identifies items with similar rating patterns and recommends items similar to those a user has rated highly. This approach is more stable than user-based methods as item preferences change less frequently than user preferences.

```{r ibcf-functions}

# Item-mean normalization function
normalize_matrix_item <- function(user_item_matrix) {
  
  # Center ratings by subtracting item mean
  item_means <- colMeans(user_item_matrix, na.rm = TRUE)
  user_item_matrix_normalized <- sweep(user_item_matrix, 2, item_means, FUN = "-")
  
  return(list(normalized = user_item_matrix_normalized, means = item_means))
}


# Cosine similarity matrix computation for items
compute_item_similarity_matrix <- function(user_item_matrix_normalized) {
  
  n_items <- ncol(user_item_matrix_normalized)
  
  # Replace NA with 0 for matrix operations
  mat <- user_item_matrix_normalized
  mat[is.na(mat)] <- 0
  
  # Transpose to work with items as rows
  mat_t <- t(mat)
  
  # Dot products between item rating vectors (numerator)
  numerator <- mat_t %*% t(mat_t)
  
  # Magnitudes (denominator)
  magnitudes <- sqrt(rowSums(mat_t^2))
  denominator <- outer(magnitudes, magnitudes)
  
  # Cosine similarity calculation
  item_similarity_matrix <- numerator / denominator
  
  # Replace NaN values with 0
  item_similarity_matrix[is.nan(item_similarity_matrix)] <- 0
  
  # Set self-similarity to 0
  diag(item_similarity_matrix) <- 0

  rownames(item_similarity_matrix) <- colnames(user_item_matrix_normalized)
  colnames(item_similarity_matrix) <- colnames(user_item_matrix_normalized)
  
  return(item_similarity_matrix)
}
```


```{r ibcf-recommendation-functions}
# Recommendation function for existing users (IBCF)
recommend_for_user_ibcf <- function(target_user, user_item_matrix,
                                    user_item_matrix_normalized, item_sim_matrix,
                                    item_means, book_info, n_recommendations = 10,
                                    k = NULL) {
  
  target_user <- as.character(target_user)
  
  # Get unrated books for target user
  unrated_books <- colnames(user_item_matrix)[is.na(user_item_matrix[target_user, ])]
  
  # Get item similarities for unrated books
  item_sims <- item_sim_matrix[unrated_books, , drop = FALSE]
  
  # Replace NA and NaN with 0
  item_sims[is.na(item_sims) | is.nan(item_sims)] <- 0
  
  # k-NN filtering – keeps only top k most similar items
  if (!is.null(k) && k < ncol(item_sims)) {
    for (i in 1:nrow(item_sims)) {
      sims <- item_sims[i, ]
      non_zero_count <- sum(sims != 0)
      if (non_zero_count > 0) {
        k_actual <- min(k, non_zero_count)
        top_k_items <- names(sort(abs(sims), decreasing = TRUE)[1:k_actual])
        sims_filtered <- rep(0, length(sims))
        names(sims_filtered) <- names(sims)
        sims_filtered[top_k_items] <- sims[top_k_items]
        item_sims[i, ] <- sims_filtered
      }
    }
  }
  
  # Check if any similar items exist
  if (sum(abs(item_sims) > 0) == 0) {
    return(data.frame())
  }
  
  # Replace NA's with 0's for matrix operations
  mat <- user_item_matrix_normalized
  mat[is.na(mat)] <- 0
  
  # Predicting ratings for unrated books using item similarities
  weighted_ratings <- item_sims %*% mat[target_user, ]
  
  # Uses only items that were rated by the user
  rated_mask <- !is.na(user_item_matrix[target_user, ])
  
  # Sum of similarities only across items the user rated
  sum_sims <- rowSums(rated_mask * abs(item_sims))
  
  # If no similar item was rated - avoid division by zero
  sum_sims[sum_sims == 0] <- 1
  
  # Calculate predictions (normalized to denormalised)
  preds <- weighted_ratings / sum_sims
  preds[is.nan(preds)] <- NA
  preds <- preds + item_means[unrated_books]
  
  # Convert matrix to named vector
  preds <- as.vector(preds)
  names(preds) <- unrated_books
  
  # Clip to valid rating range [1, 10]
  preds <- pmin(pmax(preds, 1), 10)
  
  # Get top N recommendations
  preds_valid <- preds[!is.na(preds)]
  
  if (length(preds_valid) == 0) {
    return(data.frame())
  }
  
  top_books <- sort(preds_valid, decreasing = TRUE)[1:min(n_recommendations, length(preds_valid))]
  
  # Df of recommended books & their predicted ratings
  recommendations <- data.frame(
    ISBN = names(top_books),
    Predicted_Rating = as.numeric(top_books)) %>%
    left_join(book_info, by = "ISBN") %>%
    select(ISBN, Book.Title, Book.Author, Predicted_Rating)
  
  return(recommendations)
}
```


```{r}
# Recommendation function for new users (cold start - IBCF)
recommend_for_new_user_ibcf <- function(new_user_ratings, user_item_matrix,
                                        user_item_matrix_normalized, item_means,
                                        item_sim_matrix, book_info,
                                        n_recommendations = 10, k = NULL) {
  
  # Input validation
  if (length(new_user_ratings) == 0) {
    return(data.frame())
  }
  
  # New user vector aligned with the training matrix, filled with NA
  new_user_vector <- rep(NA, ncol(user_item_matrix))
  names(new_user_vector) <- colnames(user_item_matrix)
  
  # Fill in the ratings for the user (vectorized approach)
  matched_books <- names(new_user_ratings)[names(new_user_ratings) %in% names(new_user_vector)]
  if (length(matched_books) == 0) {
    return(data.frame())
  }
  new_user_vector[matched_books] <- new_user_ratings[matched_books]
  
  # Get unrated books
  unrated_books <- names(new_user_vector)[is.na(new_user_vector)]
  
  # If user has rated all the books - empty df
  if (length(unrated_books) == 0) {
    return(data.frame())
  }
  
  # Item-mean normalisation for new user
  new_user_normalized <- new_user_vector - item_means
  new_user_vec <- new_user_normalized
  new_user_vec[is.na(new_user_vec)] <- 0
  
  # Get item similarities for unrated books
  item_sims <- item_sim_matrix[unrated_books, , drop = FALSE]
  
  # Replace NA and NaN with 0
  item_sims[is.na(item_sims) | is.nan(item_sims)] <- 0
  
  # k-NN filtering – keeps only top k most similar items
  if (!is.null(k) && k < ncol(item_sims)) {
    for (i in 1:nrow(item_sims)) {
      sims <- item_sims[i, ]
      non_zero_count <- sum(sims != 0)
      if (non_zero_count > 0) {
        k_actual <- min(k, non_zero_count)
        top_k_items <- names(sort(abs(sims), decreasing = TRUE)[1:k_actual])
        sims_filtered <- rep(0, length(sims))
        names(sims_filtered) <- names(sims)
        sims_filtered[top_k_items] <- sims[top_k_items]
        item_sims[i, ] <- sims_filtered
      }
    }
  }
  
  # Check if any similar items exist
  if (sum(abs(item_sims) > 0) == 0) {
    return(data.frame())
  }
  
  # Predicting ratings for unrated books using item similarities
  weighted_ratings <- item_sims %*% new_user_vec
  
  # Uses only items that were rated by the user
  rated_mask <- !is.na(new_user_vector)
  
  # Sum of similarities only across items the user rated
  sum_sims <- rowSums(rated_mask * abs(item_sims))
  
  # If no similar item was rated - avoid division by zero
  sum_sims[sum_sims == 0] <- 1
  
  # Calculate predictions (normalized to denormalised)
  preds <- weighted_ratings / sum_sims
  preds[is.nan(preds)] <- NA
  preds <- preds + item_means[unrated_books]
  
  # Convert matrix to named vector
  preds <- as.vector(preds)
  names(preds) <- unrated_books
  
  # Clip to valid rating range [1, 10]
  preds <- pmin(pmax(preds, 1), 10)
  
  # Get top N recommendations
  preds_valid <- preds[!is.na(preds)]
  
  if (length(preds_valid) == 0) {
    return(data.frame())
  }
  
  top_books <- sort(preds_valid, decreasing = TRUE)[1:min(n_recommendations, length(preds_valid))]
  
  # Df of recommended books & their predicted ratings
  recommendations <- data.frame(
    ISBN = names(top_books),
    Predicted_Rating = as.numeric(top_books)) %>%
    left_join(book_info, by = "ISBN") %>%
    select(ISBN, Book.Title, Book.Author, Predicted_Rating)
  
  return(recommendations)
}
```


```{r ibcf-implementation}
# ================================================================
# IBCF IMPLEMENTATION
# ================================================================

# Create user-item matrix
user_item_matrix_ibcf <- create_user_item_matrix(
  data,
  min_ratings_per_book = 5, 
  min_ratings_per_user = 2)

# Normalize matrix (item-mean)
normalized_result_ibcf <- normalize_matrix_item(user_item_matrix_ibcf)
user_item_matrix_normalized_ibcf <- normalized_result_ibcf$normalized
item_means <- normalized_result_ibcf$means

# Compute item-item similarity matrix
item_similarity_matrix <- compute_item_similarity_matrix(user_item_matrix_normalized_ibcf)

# Recommendations for existing user
sample_user <- rownames(user_item_matrix_ibcf)[3]

recs_ibcf <- recommend_for_user_ibcf(
  target_user = sample_user,
  user_item_matrix = user_item_matrix_ibcf,
  user_item_matrix_normalized = user_item_matrix_normalized_ibcf,
  item_sim_matrix = item_similarity_matrix,
  item_means = item_means,
  book_info = book_info,
  n_recommendations = 10,
  k = 50)

recs_ibcf %>%
  mutate(Rank = row_number()) %>%
  select(Rank, Book.Title, Book.Author, Predicted_Rating) %>%
  kable(caption = "Top 10 Recommendations for Existing User (IBCF)", 
        digits = 2, align = c("c", "l", "l", "c")) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), 
                full_width = FALSE)

# Recommendations for new user (cold start)
sample_books <- colnames(user_item_matrix_ibcf)[1:5]
new_user_ratings <- setNames(c(8, 9, 7, 6, 8), sample_books)

# Display new user's ratings
new_user_ratings_df <- data.frame(
  ISBN = names(new_user_ratings),
  Rating = as.numeric(new_user_ratings)) %>%
  left_join(book_info, by = "ISBN") %>%
  select(Book.Title, Book.Author, Rating)

new_user_ratings_df %>%
  kable(caption = "New User's Initial Ratings", 
        digits = 0, align = c("l", "l", "c")) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), 
                full_width = FALSE)

new_user_recs_ibcf <- recommend_for_new_user_ibcf(
  new_user_ratings = new_user_ratings,
  user_item_matrix = user_item_matrix_ibcf,
  user_item_matrix_normalized = user_item_matrix_normalized_ibcf,
  item_means = item_means,
  item_sim_matrix = item_similarity_matrix,
  book_info = book_info,
  n_recommendations = 10,
  k = 50)  

new_user_recs_ibcf %>%
  mutate(Rank = row_number()) %>%
  select(Rank, Book.Title, Book.Author, Predicted_Rating) %>%
  kable(caption = "Top 10 Recommendations for New User (IBCF)", 
        digits = 2, align = c("c", "l", "l", "c")) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), 
                full_width = FALSE)
```


```{r cross-validation-ibcf}
# ================================================================
# CROSS-VALIDATION FOR ITEM-BASED CF (FIXED)
# ================================================================

cross_validate_ibcf <- function(user_item_matrix, n_folds = 5, k = 30) {
  
  set.seed(123)
  
  # Get observed ratings
  observed <- which(!is.na(user_item_matrix), arr.ind = TRUE)
  n_ratings <- nrow(observed)
  
  # Create folds
  fold_indices <- sample(rep(1:n_folds, length.out = n_ratings))
  
  # Pre-allocate results dataframe
  cv_results <- data.frame(
    fold = integer(n_folds),
    rmse = numeric(n_folds))
  
  for (fold in 1:n_folds) {
    cat("Fold", fold, "of", n_folds, "... ")
    
    # Split data
    test_indices <- which(fold_indices == fold)
    test_obs <- observed[test_indices, , drop = FALSE]
    
    # Create train matrix
    train_matrix <- user_item_matrix
    train_matrix[test_obs] <- NA
    
    # Normalize (item-mean)
    norm_result <- normalize_matrix_item(train_matrix)
    train_normalized <- norm_result$normalized
    item_means <- norm_result$means
    
    # Compute item similarity
    item_sim_matrix <- compute_item_similarity_matrix(train_normalized)
    
    # Prepare normalized matrix for prediction
    train_norm_filled <- train_normalized
    train_norm_filled[is.na(train_norm_filled)] <- 0
    
    # Make predictions for test set
    predictions <- numeric(nrow(test_obs))
    
    for (i in 1:nrow(test_obs)) {
      user_idx <- test_obs[i, 1]
      item_idx <- test_obs[i, 2]
      
      # Get user's rated items in training set
      rated_items <- which(!is.na(train_matrix[user_idx, ]))
      
      if (length(rated_items) == 0) {
        predictions[i] <- item_means[item_idx]
        next
      }
      
      # Get similarities between target item and user's rated items
      sims <- item_sim_matrix[item_idx, rated_items]
      sims[is.na(sims) | is.nan(sims)] <- 0
      
      # Apply k-NN filtering
      if (sum(abs(sims) > 0) > 0 && k < length(sims)) {
        k_actual <- min(k, sum(abs(sims) > 0))
        top_k_idx <- order(abs(sims), decreasing = TRUE)[1:k_actual]
        sims_filtered <- rep(0, length(sims))
        sims_filtered[top_k_idx] <- sims[top_k_idx]
        sims <- sims_filtered
      }
      
      # Predict using weighted average of similar items
      if (sum(abs(sims)) > 0) {
        weighted_sum <- sum(sims * train_norm_filled[user_idx, rated_items])
        predictions[i] <- (weighted_sum / sum(abs(sims))) + item_means[item_idx]
      } else {
        predictions[i] <- item_means[item_idx]
      }
    }
    
    # Clip to valid range
    predictions <- pmin(pmax(predictions, 1), 10)
    
    # Get actual ratings
    actual <- user_item_matrix[test_obs]
    
    # Calculate metrics
    metrics <- evaluate_predictions(predictions, actual)
    
    cv_results[fold, ] <- list(fold, metrics$rmse)
    
  }
  
  return(cv_results)
}

# Run cross-validation
cv_results_ibcf <- cross_validate_ibcf(
  user_item_matrix_ibcf, 
  n_folds = 5, 
  k = 50)

# Display results
cv_results_ibcf %>%
  kable(caption = "IBCF Cross-Validation Results", 
        digits = 4, 
        col.names = c("Fold", "RMSE"),
        align = c("c", "c")) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), 
                full_width = FALSE)
```



## 4.3 Matrix Factorization-Based Collaborative Filtering

Matrix factorization decomposes the user-item rating matrix into lower-dimensional user and item factor matrices. This approach captures latent factors that explain user preferences and item characteristics, enabling more accurate predictions even with sparse data.

```{r matrix-factorization-setup}
library(recosystem)
library(dplyr)
library(caret)
```


```{r mf-data-preparation}
# ================================================================
# DATA PREPARATION FOR RECOSYSTEM
# ================================================================

prepare_recosystem_data <- function(user_item_matrix) {
  
  # DO NOT normalize - MF handles bias terms internally!
  # Convert matrix to long format with observed ratings only
  observed <- which(!is.na(user_item_matrix), arr.ind = TRUE)
  
  # Create training data with 0-based indexing 
  train_data <- data.frame(
    user_index = observed[, 1] - 1,
    item_index = observed[, 2] - 1,
    rating = user_item_matrix[observed]  # Use raw ratings
  )
  
  # Store ID mappings
  user_ids <- data.frame(
    user_index = 0:(nrow(user_item_matrix) - 1),
    user_id = rownames(user_item_matrix)
  )
  
  item_ids <- data.frame(
    item_index = 0:(ncol(user_item_matrix) - 1),
    item_id = colnames(user_item_matrix)
  )
  
  return(list(
    train_data = train_data,
    user_ids = user_ids,
    item_ids = item_ids,
    n_users = nrow(user_item_matrix),
    n_items = ncol(user_item_matrix)
  ))
}
```


```{r mf-tuning}
# ================================================================
# HYPERPARAMETER TUNING
# ================================================================

tune_reco_model <- function(train_data,
                            n_factors = c(10, 20, 30),
                            learning_rate = c(0.1, 0.05, 0.01),
                            costp_l2 = c(0.01, 0.1),
                            costq_l2 = c(0.01, 0.1),
                            n_iter = 50,
                            verbose = TRUE) {
  
  # Create data source
  train_set <- data_memory(
    user_index = train_data$user_index,
    item_index = train_data$item_index,
    rating = train_data$rating,
    index1 = FALSE
  )
  
  # Create model
  rs <- Reco()
  
  # Tune hyperparameters - CAPTURE THE RETURN VALUE!
  opts <- rs$tune(train_set, opts = list(
    dim = n_factors,
    lrate = learning_rate,
    costp_l2 = costp_l2,
    costq_l2 = costq_l2,
    niter = n_iter,
    nthread = 4,
    verbose = verbose
  ))
  
  # Return the captured opts (which contains $min)
  return(opts)
}
```


```{r mf-training}
# ================================================================
# MODEL TRAINING 
# ================================================================

train_reco_model <- function(train_data, 
                             n_factors = 20,
                             learning_rate = 0.1,
                             costp_l2 = 0.01,
                             costq_l2 = 0.01,
                             n_iter = 100,
                             n_threads = 4,
                             verbose = TRUE) {
  
  # Create data source for recosystem
  train_set <- data_memory(
    user_index = train_data$user_index,
    item_index = train_data$item_index,
    rating = train_data$rating,
    index1 = FALSE
  )
  
  # Create and train model
  rs <- Reco()
  
  rs$train(train_set, opts = list(
    dim = n_factors,
    lrate = learning_rate,
    costp_l2 = costp_l2,
    costq_l2 = costq_l2,
    niter = n_iter,
    nthread = n_threads,
    verbose = verbose
  ))
  
  return(rs)
}
```


```{r mf-evaluation}
# ================================================================
# MODEL EVALUATION
# ================================================================

evaluate_mf_model <- function(model, test_data) {
  
  # Create test data source
  test_set <- data_memory(
    user_index = test_data$user_index,
    item_index = test_data$item_index,
    rating = test_data$rating,
    index1 = FALSE
  )
  
  # Generate predictions from trained model
  predictions <- model$predict(test_set, out_memory())
  
  # Clip predictions to valid rating range [1, 10]
  predictions <- pmax(pmin(predictions, 10), 1)
  
  actual_ratings <- test_data$rating
  
  # Calculate metrics using dedicated functions
  metrics <- evaluate_predictions(predictions, actual_ratings)
  
  return(list(
    rmse = metrics$rmse,
    predictions = predictions,
    actual = actual_ratings
  ))
}
```


```{r cross-validation-mf}
# ================================================================
# CROSS-VALIDATION FOR MATRIX FACTORIZATION
# ================================================================

cross_validate_mf <- function(user_item_matrix, n_folds = 5, seed = 123,
                               n_factors = 20, learning_rate = 0.1,
                               costp_l2 = 0.01, costq_l2 = 0.01, 
                               n_iter = 50) {
  
  set.seed(seed)
  
  # Get observed ratings
  observed <- which(!is.na(user_item_matrix), arr.ind = TRUE)
  n_ratings <- nrow(observed)
  
  if (n_ratings < n_folds * 2) {
    stop("Not enough ratings for cross-validation")
  }
  
  # Create folds
  fold_indices <- sample(rep(1:n_folds, length.out = n_ratings))
  
  cv_results <- data.frame(
    fold = integer(n_folds),
    rmse = numeric(n_folds)
  )
  
  cat("Starting", n_folds, "-fold cross-validation for Matrix Factorization...\n")
  
  for (fold in 1:n_folds) {
    cat("Fold", fold, "of", n_folds, "... ")
    
    # Split data
    test_indices <- which(fold_indices == fold)
    train_indices <- which(fold_indices != fold)
    
    test_obs <- observed[test_indices, , drop = FALSE]
    train_obs <- observed[train_indices, , drop = FALSE]
    
    # Create train and test dataframes using RAW ratings
    train_data <- data.frame(
      user_index = train_obs[, 1] - 1,
      item_index = train_obs[, 2] - 1,
      rating = user_item_matrix[train_obs]
    )
    
    test_data <- data.frame(
      user_index = test_obs[, 1] - 1,
      item_index = test_obs[, 2] - 1,
      rating = user_item_matrix[test_obs]
    )
    
    # Train model
    model <- train_reco_model(
      train_data = train_data,
      n_factors = n_factors,
      learning_rate = learning_rate,
      costp_l2 = costp_l2,
      costq_l2 = costq_l2,
      n_iter = n_iter,
      verbose = FALSE
    )
    
    # Evaluate
    results <- evaluate_mf_model(model, test_data)
    
    cv_results[fold, ] <- list(fold, results$rmse)
    
    cat("RMSE:", round(results$rmse, 4), "\n")
  }
  
  # Summary
  cat("\n=== Matrix Factorization Cross-Validation Summary ===\n")
  cat("Mean RMSE:", round(mean(cv_results$rmse, na.rm = TRUE), 4), "±", 
      round(sd(cv_results$rmse, na.rm = TRUE), 4), "\n\n")
  
  return(cv_results)
}
```


```{r mf-recommendation-functions}
# ================================================================
# RECOMMENDATION FUNCTIONS
# ================================================================

# Function to recommend for existing users 
recommend_for_user_mf <- function(model, user_item_matrix, user_id, 
                                  n_recommendations = 10, 
                                  user_ids_map, item_ids_map, book_info) {
  
  # Check if user exists
  if (!user_id %in% user_ids_map$user_id) {
    stop("User ID not found in the training data")
  }
  
  # Get user's 0-based index
  user_idx <- user_ids_map$user_index[user_ids_map$user_id == user_id]
  
  # Get items user hasn't rated
  user_row <- user_item_matrix[as.character(user_id), ]
  unrated_items <- which(is.na(user_row))
  
  # Handle case where user has rated all items
  if (length(unrated_items) == 0) {
    return(data.frame())
  }
  
  # Convert to 0-based indices
  item_indices <- unrated_items - 1
  
  # Create prediction data
  pred_set <- data_memory(
    user_index = rep(user_idx, length(item_indices)),
    item_index = item_indices,
    index1 = FALSE
  )
  
  # Predict ratings
  pred_ratings <- model$predict(pred_set, out_memory())
  
  # Clip predictions to valid rating range
  pred_ratings <- pmax(pmin(pred_ratings, 10), 1)
  
  # Get top N recommendations
  n_to_recommend <- min(n_recommendations, length(pred_ratings))
  top_indices <- order(pred_ratings, decreasing = TRUE)[1:n_to_recommend]
  
  # Get item IDs for recommendations
  recommended_items <- colnames(user_item_matrix)[unrated_items[top_indices]]
  
  # Create recommendations dataframe with book details
  recommendations <- data.frame(
    ISBN = recommended_items,
    Predicted_Rating = round(pred_ratings[top_indices], 2)
  ) %>%
    left_join(book_info, by = "ISBN") %>%
    select(ISBN, Book.Title, Book.Author, Predicted_Rating)
  
  return(recommendations)
}


# Function to recommend for new users (cold start problem)
recommend_for_new_user_mf <- function(model, new_user_ratings, 
                                      user_item_matrix, item_ids_map, 
                                      book_info, n_recommendations = 10) {
  
  # Input validation
  if (length(new_user_ratings) == 0) {
    return(data.frame())
  }
  
  # Convert named vector to proper format
  if (is.numeric(new_user_ratings) && !is.null(names(new_user_ratings))) {
    ratings_df <- data.frame(
      item_id = names(new_user_ratings),
      rating = as.numeric(new_user_ratings),
      stringsAsFactors = FALSE
    )
  } else {
    ratings_df <- new_user_ratings
  }
  
  # Check which items exist in training data
  valid_items <- ratings_df$item_id %in% item_ids_map$item_id
  if (sum(valid_items) == 0) {
    stop("None of the provided items exist in the training data")
  }
  
  # Filter to valid items only
  ratings_df <- ratings_df[valid_items, ]
  
  # Get item indices for rated items
  rated_item_ids <- ratings_df$item_id
  rated_indices <- item_ids_map$item_index[match(rated_item_ids, item_ids_map$item_id)]
  
  # Create temporary user index (outside existing user range)
  temp_user_idx <- nrow(user_item_matrix)
  
  # Get all unrated items (all items minus the ones user rated)
  all_item_indices <- 0:(nrow(item_ids_map) - 1)
  unrated_indices <- setdiff(all_item_indices, rated_indices)
  
  if (length(unrated_indices) == 0) {
    return(data.frame())
  }
  
  # Create prediction set for unrated items only
  pred_set <- data_memory(
    user_index = rep(temp_user_idx, length(unrated_indices)),
    item_index = unrated_indices,
    index1 = FALSE
  )
  
  # Predict ratings
  pred_ratings <- model$predict(pred_set, out_memory())
  
  # Clip to valid range [1, 10]
  pred_ratings <- pmax(pmin(pred_ratings, 10), 1)
  
  # Get top recommendations
  n_to_recommend <- min(n_recommendations, length(pred_ratings))
  top_indices <- order(pred_ratings, decreasing = TRUE)[1:n_to_recommend]
  
  # Get recommended item IDs
  recommended_item_ids <- item_ids_map$item_id[match(unrated_indices[top_indices], 
                                                      item_ids_map$item_index)]
  
  # Create recommendations dataframe with book details
  recommendations <- data.frame(
    ISBN = recommended_item_ids,
    Predicted_Rating = round(pred_ratings[top_indices], 2)
  ) %>%
    left_join(book_info, by = "ISBN") %>%
    select(ISBN, Book.Title, Book.Author, Predicted_Rating)
  
  return(recommendations)
}
```


```{r mf-implementation}
# ================================================================
# MATRIX FACTORIZATION IMPLEMENTATION
# ================================================================

# Create user-item matrix (use the same one for consistency)
user_item_matrix_mf <- create_user_item_matrix(
  data,
  min_ratings_per_book = 5, 
  min_ratings_per_user = 2)

# Prepare data for recosystem
prepared <- prepare_recosystem_data(user_item_matrix_mf)

cat("Data prepared for Matrix Factorization:\n")
cat("Users:", prepared$n_users, "\n")
cat("Items:", prepared$n_items, "\n")
cat("Ratings:", nrow(prepared$train_data), "\n\n")

# Hyperparameter Optimization
cat("Starting hyperparameter tuning...\n")
optimal_params <- tune_reco_model(
  train_data = prepared$train_data,
  n_factors = c(10, 20, 30),
  learning_rate = c(0.1, 0.05, 0.01),
  costp_l2 = c(0.01, 0.1),
  costq_l2 = c(0.01, 0.1),
  n_iter = 50,
  verbose = FALSE
)

cat("\nOptimal hyperparameters found:\n")
cat("n_factors:", optimal_params$min$dim, "\n")
cat("learning_rate:", optimal_params$min$lrate, "\n")
cat("costp_l2:", optimal_params$min$costp_l2, "\n")
cat("costq_l2:", optimal_params$min$costq_l2, "\n\n")

# Cross-Validation with optimal parameters
mf_cv_results <- cross_validate_mf(
  user_item_matrix_mf, 
  n_folds = 5,
  n_factors = optimal_params$min$dim,
  learning_rate = optimal_params$min$lrate,
  costp_l2 = optimal_params$min$costp_l2,
  costq_l2 = optimal_params$min$costq_l2,
  n_iter = 50
)

# Display cross-validation results
mf_cv_results %>%
  kable(caption = "Matrix Factorization Cross-Validation Results", 
        digits = 4, 
        col.names = c("Fold", "RMSE"),
        align = c("c", "c")) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), 
                full_width = FALSE)

# Train Final Model with optimal parameters
cat("Training final model with optimal parameters...\n")
model_mf <- train_reco_model(
  train_data = prepared$train_data,
  n_factors = optimal_params$min$dim,
  learning_rate = optimal_params$min$lrate,
  costp_l2 = optimal_params$min$costp_l2,
  costq_l2 = optimal_params$min$costq_l2,
  n_iter = 100,
  n_threads = 4,
  verbose = FALSE
)

cat("Model training complete!\n\n")
```


```{r mf-recommendations}
# ================================================================
# GENERATE RECOMMENDATIONS
# ================================================================

### RECOMMENDATIONS FOR EXISTING USER 
sample_user <- rownames(user_item_matrix_mf)[3]

recs_mf <- recommend_for_user_mf(
  model = model_mf,
  user_item_matrix = user_item_matrix_mf,
  user_id = sample_user,
  n_recommendations = 10,
  user_ids_map = prepared$user_ids,
  item_ids_map = prepared$item_ids,
  book_info = book_info
)

recs_mf %>%
  mutate(Rank = row_number()) %>%
  select(Rank, Book.Title, Book.Author, Predicted_Rating) %>%
  kable(caption = "Top 10 Recommendations for Existing User (Matrix Factorization)", 
        digits = 2, align = c("c", "l", "l", "c")) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), 
                full_width = FALSE)


### RECOMMENDATIONS FOR NEW USER 

# Simulate new user with 5 book ratings
sample_books <- colnames(user_item_matrix_mf)[1:5]
new_user_ratings <- setNames(c(8, 9, 7, 6, 8), sample_books)

# Display new user's ratings
new_user_ratings_df <- data.frame(
  ISBN = names(new_user_ratings),
  Rating = as.numeric(new_user_ratings)) %>%
  left_join(book_info, by = "ISBN") %>%
  select(Book.Title, Book.Author, Rating)

new_user_ratings_df %>%
  kable(caption = "New User's Initial Ratings", 
        digits = 0, align = c("l", "l", "c")) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), 
                full_width = FALSE)

# Get recommendations for new user
new_user_recs_mf <- recommend_for_new_user_mf(
  model = model_mf,
  new_user_ratings = new_user_ratings,
  user_item_matrix = user_item_matrix_mf,
  item_ids_map = prepared$item_ids,
  book_info = book_info,
  n_recommendations = 10
)

new_user_recs_mf %>%
  mutate(Rank = row_number()) %>%
  select(Rank, Book.Title, Book.Author, Predicted_Rating) %>%
  kable(caption = "Top 10 Recommendations for New User (Matrix Factorization)", 
        digits = 2, align = c("c", "l", "l", "c")) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), 
                full_width = FALSE)
```



## 4.4 Neural Network-Based Collaborative Filtering

Neural networks can learn complex non-linear relationships between users and items through deep learning architectures. H2O's Deep Learning implementation provides scalable neural network training with hyperparameter optimization capabilities.

```{r nn-setup}
library(h2o)
library(dplyr)
library(kableExtra)
```


```{r nn-data-preparation}
# ================================================================
# DATA PREPARATION FOR H2O
# ================================================================

prepare_h2o_data <- function(user_item_matrix) {
  
  # Apply user-mean normalization
  user_means <- rowMeans(user_item_matrix, na.rm = TRUE)
  normalized_matrix <- sweep(user_item_matrix, 1, user_means, FUN = "-")
  
  # Get observed ratings
  observed <- which(!is.na(normalized_matrix), arr.ind = TRUE)
  
  # Create training data with normalized ratings
  train_data <- data.frame(
    user_id = rownames(user_item_matrix)[observed[, 1]],
    book_id = colnames(user_item_matrix)[observed[, 2]],
    rating = as.numeric(normalized_matrix[observed])
  )
  
  # Store ID mappings
  user_ids <- data.frame(user_id = rownames(user_item_matrix))
  book_ids <- data.frame(book_id = colnames(user_item_matrix))
  
  return(list(
    train_data = train_data,
    user_ids = user_ids,
    book_ids = book_ids,
    n_users = nrow(user_item_matrix),
    n_items = ncol(user_item_matrix),
    user_means = user_means,
    original_matrix = user_item_matrix
  ))
}
```


```{r nn-tuning}
# ================================================================
# HYPERPARAMETER TUNING
# ================================================================

# Initialize H2O cluster
h2o.init(nthreads = -1, max_mem_size = "4G")

# Create user-item matrix (use the same one for consistency)
user_item_matrix_nn <- create_user_item_matrix(
  data,
  min_ratings_per_book = 5, 
  min_ratings_per_user = 3)

# Prepare data for hyperparameter tuning
h2o_data_tuning <- prepare_h2o_data(user_item_matrix_nn)

# Parameter search space
activation_opt <- c("Rectifier", "RectifierWithDropout", "Tanh", "TanhWithDropout")
hidden_opt <- list(
  c(32, 16), c(64, 32), c(32, 32), c(64, 64), 
  c(16, 16), c(48, 24), c(24, 12), c(32, 16, 8)
)
l1_opt <- c(1e-3, 1e-5, 1e-7)
l2_opt <- c(1e-3, 1e-5, 1e-7)
epochs_opt <- c(10, 15, 20)

# Hyperparameter grid
hyper_params <- list(
  activation = activation_opt,
  hidden = hidden_opt,
  l1 = l1_opt,
  l2 = l2_opt,
  epochs = epochs_opt
)

# Set seed for reproducibility
set.seed(123)

# Convert training data to H2O frame for grid search
train_h2o_tuning <- as.h2o(h2o_data_tuning$train_data)
train_h2o_tuning$user_id <- as.factor(train_h2o_tuning$user_id)
train_h2o_tuning$book_id <- as.factor(train_h2o_tuning$book_id)

cat("Starting hyperparameter grid search...\n")

# Run H2O grid search
model_grid <- h2o.grid(
  "deeplearning",
  grid_id = "nn_grid_book_recommendations",
  hyper_params = hyper_params,
  x = c("user_id", "book_id"),
  y = "rating",
  seed = 123,
  reproducible = TRUE,
  training_frame = train_h2o_tuning,
  nfolds = 5,  
  stopping_rounds = 2,
  stopping_metric = "RMSE",
  stopping_tolerance = 0.001,
  adaptive_rate = TRUE
)

# Get grid results sorted by RMSE (ascending - best first)
grid_results <- h2o.getGrid("nn_grid_book_recommendations", sort_by = "rmse", decreasing = FALSE)

# Display top 5 models
cat("\nTop 5 models from grid search:\n")
kable(grid_results@summary_table[1:min(5, nrow(grid_results@summary_table)), ], 
      caption = "Top 5 Neural Network Models from Grid Search") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), 
                full_width = FALSE)

# Get best model
best_model_id <- grid_results@model_ids[[1]]
best_model <- h2o.getModel(best_model_id)

# Get cross-validation error
cv_rmse <- best_model@model$cross_validation_metrics_summary["rmse", ]

# Create results table
best_nn_results <- data.frame(
  Activation = best_model@allparameters$activation,
  Hidden_Layers = paste(best_model@allparameters$hidden, collapse = ", "),
  L1_Regularisation = best_model@allparameters$l1,
  L2_Regularisation = best_model@allparameters$l2,
  Epochs = best_model@allparameters$epochs,
  CV_RMSE = round(cv_rmse$mean, 3)
)

cat("\nOptimal hyperparameters:\n")
kable(best_nn_results, 
      caption = "Best Neural Network Model Specifications") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), 
                full_width = FALSE)
```


```{r nn-training}
# ================================================================
# MODEL TRAINING
# ================================================================

train_h2o_model <- function(train_data,
                            hidden = c(64, 32),
                            epochs = 30,
                            activation = "Rectifier",
                            hidden_dropout_ratios = c(0.3, 0.3),
                            l1 = 0.00001,
                            l2 = 0.00001,
                            adaptive_rate = TRUE,
                            rate = 0.001,
                            seed = 123,
                            verbose = TRUE) {
  
  h2o.no_progress()
  
  features <- c("user_id", "book_id")
  response <- "rating"
  
  model <- h2o.deeplearning(
    x = features,
    y = response,
    training_frame = train_data,
    hidden = hidden,
    epochs = epochs,
    activation = activation,
    hidden_dropout_ratios = hidden_dropout_ratios,
    l1 = l1,
    l2 = l2,
    adaptive_rate = adaptive_rate,
    rate = rate,
    seed = seed,
    verbose = verbose
  )
  
  return(model)
}
```


```{r nn-evaluation}
# ================================================================
# MODEL EVALUATION
# ================================================================

evaluate_h2o_model <- function(model, test_data, user_means) {
  
  # Generate predictions
  predictions <- h2o.predict(model, test_data)
  predictions_df <- as.data.frame(predictions)
  test_data_df <- as.data.frame(test_data)
  
  # Denormalize predictions (add back user means)
  user_ids_for_test <- test_data_df$user_id
  user_means_for_test <- user_means[as.character(user_ids_for_test)]
  predictions_df$predict <- predictions_df$predict + user_means_for_test
  
  # Clip predictions to valid rating range [1, 10]
  predictions_df$predict <- pmax(pmin(predictions_df$predict, 10), 1)
  
  # Get actual values
  actual_df <- as.data.frame(test_data$rating)
  
  # Calculate metrics using dedicated functions
  metrics <- evaluate_predictions(predictions_df$predict, actual_df$rating)
  
  return(list(
    rmse = metrics$rmse,
    predictions = predictions_df$predict,
    actual = actual_df$rating
  ))
}
```


```{r cross-validation-nn}
# ================================================================
# CROSS-VALIDATION FOR NEURAL NETWORK
# ================================================================

cross_validate_nn <- function(user_item_matrix, n_folds = 5, seed = 123, 
                               hidden = c(64, 32), epochs = 20, 
                               activation = "Rectifier",
                               hidden_dropout_ratios = NULL,
                               l1 = 0.00001, l2 = 0.00001) {
  
  set.seed(seed)
  h2o.no_progress()
  
  # Apply user-mean normalization
  user_means <- rowMeans(user_item_matrix, na.rm = TRUE)
  normalized_matrix <- sweep(user_item_matrix, 1, user_means, FUN = "-")
  
  # Get observed ratings
  observed <- which(!is.na(normalized_matrix), arr.ind = TRUE)
  n_ratings <- nrow(observed)
  
  if (n_ratings < n_folds * 2) {
    stop("Not enough ratings for cross-validation")
  }
  
  # Create folds
  fold_indices <- sample(rep(1:n_folds, length.out = n_ratings))
  
  cv_results <- data.frame(
    fold = integer(n_folds),
    rmse = numeric(n_folds)
  )
  
  cat("Starting", n_folds, "-fold cross-validation for Neural Network...\n")
  
  for (fold in 1:n_folds) {
    cat("Fold", fold, "of", n_folds, "... ")
    
    # Split data
    test_indices <- which(fold_indices == fold)
    train_indices <- which(fold_indices != fold)
    
    test_obs <- observed[test_indices, , drop = FALSE]
    train_obs <- observed[train_indices, , drop = FALSE]
    
    # Create train dataframe with normalized ratings
    train_data <- data.frame(
      user_id = rownames(user_item_matrix)[train_obs[, 1]],
      book_id = colnames(user_item_matrix)[train_obs[, 2]],
      rating = as.numeric(normalized_matrix[train_obs])
    )
    
    # Create test dataframe with original ratings (for proper evaluation)
    test_data <- data.frame(
      user_id = rownames(user_item_matrix)[test_obs[, 1]],
      book_id = colnames(user_item_matrix)[test_obs[, 2]],
      rating = as.numeric(user_item_matrix[test_obs])
    )
    
    # Convert to H2O frames
    train_h2o <- as.h2o(train_data)
    test_h2o <- as.h2o(test_data)
    train_h2o$user_id <- as.factor(train_h2o$user_id)
    train_h2o$book_id <- as.factor(train_h2o$book_id)
    test_h2o$user_id <- as.factor(test_h2o$user_id)
    test_h2o$book_id <- as.factor(test_h2o$book_id)
    
    # Train model with specified hyperparameters
    model <- train_h2o_model(
      train_data = train_h2o,
      hidden = hidden,
      epochs = epochs,
      activation = activation,
      hidden_dropout_ratios = hidden_dropout_ratios,
      l1 = l1,
      l2 = l2,
      verbose = FALSE
    )
    
    # Evaluate
    results <- evaluate_h2o_model(model, test_h2o, user_means)
    
    cv_results[fold, ] <- list(fold, results$rmse)
    
    cat("RMSE:", round(results$rmse, 4), "\n")
    
    # Clear model to free memory
    h2o.rm(model)
    h2o.rm(train_h2o)
    h2o.rm(test_h2o)
    gc()
  }
  
  # Summary
  cat("\n=== Neural Network Cross-Validation Summary ===\n")
  cat("Mean RMSE:", round(mean(cv_results$rmse, na.rm = TRUE), 4), "±", 
      round(sd(cv_results$rmse, na.rm = TRUE), 4), "\n\n")
  
  return(cv_results)
}
```


```{r nn-recommendation-functions}
# ================================================================
# RECOMMENDATION FUNCTIONS
# ================================================================

# Function to recommend for existing users
recommend_for_user_nn <- function(model, user_item_matrix, user_id,
                                  n_recommendations = 10,
                                  user_ids, book_ids, user_means, book_info) {
  
  # Check if user exists
  if (!user_id %in% user_ids$user_id) {
    stop("User ID not found in the training data")
  }
  
  # Get books user hasn't rated
  user_row <- user_item_matrix[as.character(user_id), ]
  unrated_books <- which(is.na(user_row))
  
  # Handle case where user has rated all books
  if (length(unrated_books) == 0) {
    return(data.frame())
  }
  
  # Create prediction data
  pred_data <- data.frame(
    user_id = rep(user_id, length(unrated_books)),
    book_id = colnames(user_item_matrix)[unrated_books]
  )
  
  # Convert to H2O frame
  pred_h2o <- as.h2o(pred_data)
  pred_h2o$user_id <- as.factor(pred_h2o$user_id)
  pred_h2o$book_id <- as.factor(pred_h2o$book_id)
  
  # Predict ratings
  predictions <- h2o.predict(model, pred_h2o)
  predictions_df <- as.data.frame(predictions)
  
  # Denormalize predictions (add back user mean)
  user_mean <- user_means[user_id]
  pred_ratings <- predictions_df$predict + user_mean
  
  # Clip predictions to valid rating range
  pred_ratings <- pmax(pmin(pred_ratings, 10), 1)
  
  # Get top N recommendations
  n_to_recommend <- min(n_recommendations, length(pred_ratings))
  top_indices <- order(pred_ratings, decreasing = TRUE)[1:n_to_recommend]
  
  # Create recommendations dataframe with book details
  recommendations <- data.frame(
    ISBN = pred_data$book_id[top_indices],
    Predicted_Rating = round(pred_ratings[top_indices], 2)
  ) %>%
    left_join(book_info, by = "ISBN") %>%
    select(ISBN, Book.Title, Book.Author, Predicted_Rating)
  
  return(recommendations)
}


# Function to recommend for new users (cold start problem)
recommend_for_new_user_nn <- function(model, new_user_ratings, book_ids,
                                      book_info, n_recommendations = 10, 
                                      user_means = NULL) {
  
  # Input validation
  if (length(new_user_ratings) == 0) {
    return(data.frame())
  }
  
  # Convert named vector to data frame if needed
  if (is.numeric(new_user_ratings) && !is.null(names(new_user_ratings))) {
    ratings_df <- data.frame(
      book_id = names(new_user_ratings),
      rating = as.numeric(new_user_ratings),
      stringsAsFactors = FALSE
    )
  } else {
    ratings_df <- new_user_ratings
  }
  
  # Check which books exist in training data
  valid_books <- ratings_df$book_id %in% book_ids$book_id
  if (sum(valid_books) == 0) {
    stop("None of the provided books exist in the training data")
  }
  
  # Filter to valid books
  ratings_df <- ratings_df[valid_books, ]
  
  # Get unrated books
  rated_books <- ratings_df$book_id
  unrated_books <- setdiff(book_ids$book_id, rated_books)
  
  if (length(unrated_books) == 0) {
    return(data.frame())
  }
  
  # Create temporary user ID for predictions
  temp_user_id <- "temp_user_nn"
  
  # Create prediction data for all unrated books
  pred_data <- data.frame(
    user_id = rep(temp_user_id, length(unrated_books)),
    book_id = unrated_books,
    stringsAsFactors = FALSE
  )
  
  # Convert to H2O frame
  pred_h2o <- as.h2o(pred_data)
  pred_h2o$user_id <- as.factor(pred_h2o$user_id)
  pred_h2o$book_id <- as.factor(pred_h2o$book_id)
  
  # Predict ratings
  predictions <- h2o.predict(model, pred_h2o)
  predictions_df <- as.data.frame(predictions)
  
  # Denormalize predictions if user_means provided
  if (!is.null(user_means)) {
    new_user_mean <- mean(ratings_df$rating, na.rm = TRUE)
    pred_ratings <- predictions_df$predict + new_user_mean
  } else {
    pred_ratings <- predictions_df$predict
  }
  
  # Clip predictions to valid rating range
  pred_ratings <- pmax(pmin(pred_ratings, 10), 1)
  
  # Get top recommendations
  n_to_recommend <- min(n_recommendations, length(pred_ratings))
  top_indices <- order(pred_ratings, decreasing = TRUE)[1:n_to_recommend]
  
  # Create recommendations dataframe with book details
  recommendations <- data.frame(
    ISBN = pred_data$book_id[top_indices],
    Predicted_Rating = round(pred_ratings[top_indices], 2)
  ) %>%
    left_join(book_info, by = "ISBN") %>%
    select(ISBN, Book.Title, Book.Author, Predicted_Rating)
  
  return(recommendations)
}
```


```{r nn-implementation}
# ================================================================
# NEURAL NETWORK IMPLEMENTATION
# ================================================================

# Prepare data for final model
prepared <- prepare_h2o_data(user_item_matrix_nn)

cat("Data prepared for Neural Network:\n")
cat("Users:", prepared$n_users, "\n")
cat("Items:", prepared$n_items, "\n")
cat("Ratings:", nrow(prepared$train_data), "\n\n")

# Extract optimal parameters from grid search results
optimal_params <- list(
  hidden = best_model@allparameters$hidden,
  epochs = best_model@allparameters$epochs,
  activation = best_model@allparameters$activation,
  hidden_dropout_ratios = best_model@allparameters$hidden_dropout_ratios,
  l1 = best_model@allparameters$l1,
  l2 = best_model@allparameters$l2
)

cat("Using optimal parameters:\n")
print(optimal_params)

# Cross-Validation with optimal parameters
nn_cv_results <- cross_validate_nn(
  user_item_matrix_nn, 
  n_folds = 5,
  hidden = optimal_params$hidden,
  epochs = optimal_params$epochs,
  activation = optimal_params$activation,
  hidden_dropout_ratios = optimal_params$hidden_dropout_ratios,
  l1 = optimal_params$l1,
  l2 = optimal_params$l2
)

# Display cross-validation results
nn_cv_results %>%
  kable(caption = "Neural Network Cross-Validation Results", 
        digits = 4, 
        col.names = c("Fold", "RMSE"),
        align = c("c", "c")) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), 
                full_width = FALSE)

# Train Final Model for Recommendations
cat("\nTraining final model with optimal parameters...\n")

# Convert training data to H2O frame
train_h2o <- as.h2o(prepared$train_data)
train_h2o$user_id <- as.factor(train_h2o$user_id)
train_h2o$book_id <- as.factor(train_h2o$book_id)

# Train final model with optimal parameters
model_nn <- train_h2o_model(
  train_data = train_h2o,
  hidden = optimal_params$hidden,
  epochs = optimal_params$epochs,
  activation = optimal_params$activation,
  hidden_dropout_ratios = optimal_params$hidden_dropout_ratios,
  l1 = optimal_params$l1,
  l2 = optimal_params$l2,
  verbose = FALSE
)

cat("Model training complete!\n\n")
```


```{r nn-recommendations}
# ================================================================
# GENERATE RECOMMENDATIONS
# ================================================================

### RECOMMENDATIONS FOR EXISTING USER
sample_user <- rownames(user_item_matrix_nn)[3]

recs_nn <- recommend_for_user_nn(
  model = model_nn,
  user_item_matrix = user_item_matrix_nn,
  user_id = sample_user,
  n_recommendations = 10,
  user_ids = prepared$user_ids,
  book_ids = prepared$book_ids,
  user_means = prepared$user_means,
  book_info = book_info
)

recs_nn %>%
  mutate(Rank = row_number()) %>%
  select(Rank, Book.Title, Book.Author, Predicted_Rating) %>%
  kable(caption = "Top 10 Recommendations for Existing User (Neural Network)", 
        digits = 2, align = c("c", "l", "l", "c")) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), 
                full_width = FALSE)


### RECOMMENDATIONS FOR NEW USER

# Simulate new user with 5 book ratings
sample_books <- colnames(user_item_matrix_nn)[1:5]
new_user_ratings <- setNames(c(8, 9, 7, 6, 8), sample_books)

# Display new user's ratings
new_user_ratings_df <- data.frame(
  ISBN = names(new_user_ratings),
  Rating = as.numeric(new_user_ratings)
) %>%
  left_join(book_info, by = "ISBN") %>%
  select(Book.Title, Book.Author, Rating)

new_user_ratings_df %>%
  kable(caption = "New User's Initial Ratings", 
        digits = 0, align = c("l", "l", "c")) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), 
                full_width = FALSE)

# Get recommendations for new user
new_user_recs_nn <- recommend_for_new_user_nn(
  model = model_nn,
  new_user_ratings = new_user_ratings,
  book_ids = prepared$book_ids,
  book_info = book_info,
  n_recommendations = 10,
  user_means = prepared$user_means
)

new_user_recs_nn %>%
  mutate(Rank = row_number()) %>%
  select(Rank, Book.Title, Book.Author, Predicted_Rating) %>%
  kable(caption = "Top 10 Recommendations for New User (Neural Network)", 
        digits = 2, align = c("c", "l", "l", "c")) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), 
                full_width = FALSE)

# Clean up H2O cluster
h2o.shutdown(prompt = FALSE)
```




# 5. Results and Analysis

## 5.1 Cross-Validation Performance Analysis

```{r comprehensive-analysis-setup}
# This script adds the three critical missing components:
# 1. Cross-validation comparison for all 4 methods
# 2. Dataset size vs accuracy analysis  
# 3. Unified performance comparison and conclusions

# NOTE: Make sure you've already run all previous sections and have:
# - user_item_matrix (from any of your CF sections)
# - book_info, book_ratings, data loaded
# - All your functions defined (UBCF, IBCF, MF, NN)

library(tidyverse)
library(kableExtra)
library(recosystem)
library(h2o)
```




```{r ubcf-ibcf-comparison}
# ================================================================
# UBCF vs IBCF COMPARISON
# ================================================================

# Create shared matrix for fair comparison
user_item_matrix_cv <- create_user_item_matrix(
  data,
  min_ratings_per_book = 5,
  min_ratings_per_user = 2
)

# Run cross-validation for UBCF
cv_results_ubcf <- cross_validate_ubcf(
  user_item_matrix = user_item_matrix_cv,
  n_folds = 5,
  k = 50
)

# Run cross-validation for IBCF
cv_results_ibcf <- cross_validate_ibcf(
  user_item_matrix = user_item_matrix_cv,
  n_folds = 5,
  k = 50
)

# Combine results for comparison
cv_results_ubcf$method <- "UBCF"
cv_results_ibcf$method <- "IBCF"
cv_results_combined <- rbind(cv_results_ubcf, cv_results_ibcf)

# Display summary table
summary_stats <- cv_results_combined %>%
  group_by(method) %>%
  summarise(
    Mean_RMSE = mean(rmse, na.rm = TRUE),
    SD_RMSE = sd(rmse, na.rm = TRUE),
    .groups = "drop"
  )

summary_stats %>%
  mutate(across(where(is.numeric), ~round(., 4))) %>%
  kable(caption = "Cross-Validation Results: UBCF vs IBCF", 
        align = c("l", rep("c", 2))) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"),
                full_width = FALSE)
```

```{r comprehensive-cv-comparison}
# ================================================================
# PART 3: COMPREHENSIVE CROSS-VALIDATION COMPARISON
# ================================================================

run_comprehensive_cv_comparison <- function(user_item_matrix, n_folds = 5, optimal_params) {
  
  # Initialize H2O cluster once for all neural network operations
  h2o.init(nthreads = -1, max_mem_size = "4G")
  h2o.no_progress()
  
  # Pre-allocate results dataframe for efficiency
  all_results <- data.frame(
    Method = character(4),
    CV_RMSE_Mean = numeric(4),
    CV_RMSE_SD = numeric(4),
    Implementation = character(4),
    stringsAsFactors = FALSE
  )
  
  # 1. Item-Based CF
    ibcf_cv <- cross_validate_ibcf(user_item_matrix, n_folds)
  all_results[1, ] <- list(
    "Item-Based CF",
    round(mean(ibcf_cv$rmse), 3),
    round(sd(ibcf_cv$rmse), 3),
    "Scratch"
  )
  
  # 2. User-Based CF
    ubcf_cv <- cross_validate_ubcf(user_item_matrix, n_folds)
  all_results[2, ] <- list(
    "User-Based CF",
    round(mean(ubcf_cv$rmse), 3),
    round(sd(ubcf_cv$rmse), 3),
    "Scratch"
  )
  
  # 3. Matrix Factorization
    mf_cv <- cross_validate_mf(user_item_matrix, n_folds)
  all_results[3, ] <- list(
    "Matrix Factorization",
    round(mean(mf_cv$fold_results$rmse), 3),
    round(sd(mf_cv$fold_results$rmse), 3),
    "recosystem"
  )
  
  # 4. Neural Network
  nn_cv <- cross_validate_h2o(user_item_matrix, n_folds, optimal_params = optimal_params)
  all_results[4, ] <- list(
    "Neural Network",
    round(mean(nn_cv$fold_results$rmse), 3),
    round(sd(nn_cv$fold_results$rmse), 3),
    "h2o"
  )
  
  # Clean up H2O cluster
  h2o.shutdown(prompt = FALSE)
  
  return(all_results)
}


# Run the comprehensive comparison
cv_comparison_results <- run_comprehensive_cv_comparison(user_item_matrix, n_folds = 5, optimal_params = optimal_params)

# Display results in formatted table
kable(cv_comparison_results, 
      caption = "Cross-Validation Performance Comparison - All Methods",
      format = "html") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"),
                full_width = FALSE,
                position = "center") %>%
  column_spec(2:3, color = "blue") %>%
  add_footnote("Note: Lower RMSE values indicate better performance")
```

## 5.2 Dataset Size Impact Analysis

### 5.2.1 Comprehensive Dataset Size Testing


### 5.2.2 Diminishing Returns Analysis

```{r diminishing-returns}
# ================================================================
# DIMINISHING RETURNS ANALYSIS - KEY ASSIGNMENT QUESTION
# ================================================================

if (exists("dataset_size_results") && nrow(dataset_size_results) > 0) {
  
  cat("\n=== DIMINISHING RETURNS ANALYSIS ===\n")
  cat("Determining if there's a point where adding more books doesn't improve accuracy\n\n")
  
  # Analyze each method for diminishing returns
  methods <- unique(dataset_size_results$Method)
  
  for (method in methods) {
    method_data <- dataset_size_results %>%
      filter(Method == method) %>%
      arrange(Dataset_Size)
    
    if (nrow(method_data) >= 3) {
      cat("---", method, "---\n")
      
      # Calculate improvement rates
      improvements <- numeric()
      for (i in 2:nrow(method_data)) {
        prev_rmse <- method_data$RMSE[i-1]
        curr_rmse <- method_data$RMSE[i]
        improvement <- ((prev_rmse - curr_rmse) / prev_rmse) * 100
        improvements <- c(improvements, improvement)
        
        cat("Improvement from", method_data$Dataset_Size[i-1], "to", 
            method_data$Dataset_Size[i], "books:", 
            round(improvement, 2), "%\n")
      }
      
      # Find point of diminishing returns (improvement < 2%)
      diminishing_point <- which(improvements < 2)[1]
      if (!is.na(diminishing_point)) {
        optimal_size <- method_data$Dataset_Size[diminishing_point]
        cat("→ Diminishing returns point:", optimal_size, "books\n")
        cat("→ Optimal catalog size for", method, ":", optimal_size, "books\n\n")
      } else {
        cat("→ No clear diminishing returns point found\n\n")
      }
    }
  }
  
  # Create visualization
  if (nrow(dataset_size_results) > 0) {
    p_size <- ggplot(dataset_size_results, aes(x = Dataset_Size, y = RMSE, 
                                               color = Method, group = Method)) +
      geom_line(size = 1.2) +
      geom_point(size = 3) +
      labs(title = "Predictive Accuracy vs Dataset Size",
           subtitle = "Impact of Catalog Size on RMSE Performance",
           x = "Number of Books in Dataset",
           y = "RMSE (Lower is Better)",
           color = "Method") +
      theme_minimal() +
      theme(legend.position = "bottom",
            plot.title = element_text(face = "bold"),
            plot.subtitle = element_text(color = "gray60")) +
      scale_x_continuous(breaks = unique(dataset_size_results$Dataset_Size))
    
    print(p_size)
  }
  
} else {
  cat("Dataset size results not available for diminishing returns analysis\n")
}
```

```{r dataset-size-analysis}
# ================================================================
# PART 4: DATASET SIZE VS ACCURACY ANALYSIS (REQUIREMENT 3)
# ================================================================

analyze_dataset_size_impact <- function(data, book_sizes = c(30, 60, 90, 120, 150), 
                                        n_folds = 3, optimal_params) {
  
  # Initialize H2O cluster once for all neural network operations
  h2o.init(nthreads = -1, max_mem_size = "4G")
  h2o.no_progress()
  
  # Pre-allocate results dataframe for efficiency
  n_total_results <- length(book_sizes) * 4
  results <- data.frame(
    Dataset_Size = integer(n_total_results),
    Method = character(n_total_results),
    RMSE = numeric(n_total_results),
    Users = integer(n_total_results),
    Books = integer(n_total_results),
    Sparsity = numeric(n_total_results),
    stringsAsFactors = FALSE
  )
  
  result_idx <- 1
  
  for (n_books in book_sizes) {
    # Sample books
    available_books <- unique(data$ISBN)
    sampled_books <- sample(available_books, min(n_books, length(available_books)))
    subset_data <- data %>% filter(ISBN %in% sampled_books)
    
    # Create matrix
    subset_matrix <- create_user_item_matrix(
      subset_data, 
      min_ratings_per_book = 3, 
      min_ratings_per_user = 2
    )
    
    n_users <- nrow(subset_matrix)
    n_items <- ncol(subset_matrix)
    sparsity <- round(mean(is.na(subset_matrix)) * 100, 2)
    
    # Evaluate Item-Based CF
    ibcf_cv <- cross_validate_ibcf(subset_matrix, n_folds = n_folds, k = 30)
    results[result_idx, ] <- list(n_books, "Item-Based CF", round(mean(ibcf_cv$rmse), 3), n_users, n_items, sparsity)
    result_idx <- result_idx + 1
    
    # Evaluate User-Based CF
    ubcf_cv <- cross_validate_ubcf(subset_matrix, n_folds = n_folds, k = 30)
    results[result_idx, ] <- list(n_books, "User-Based CF", round(mean(ubcf_cv$rmse), 3), n_users, n_items, sparsity)
    result_idx <- result_idx + 1
    
    # Evaluate Matrix Factorization
    mf_cv <- cross_validate_mf(subset_matrix, n_folds = n_folds)
    results[result_idx, ] <- list(n_books, "Matrix Factorization", round(mean(mf_cv$fold_results$rmse), 3), n_users, n_items, sparsity)
    result_idx <- result_idx + 1
    
    # Evaluate Neural Network
    nn_cv <- cross_validate_h2o(subset_matrix, n_folds = n_folds, optimal_params = optimal_params)
    results[result_idx, ] <- list(n_books, "Neural Network", round(mean(nn_cv$fold_results$rmse), 3), n_users, n_items, sparsity)
    result_idx <- result_idx + 1
  }
  
  # Clean up H2O cluster
  h2o.shutdown(prompt = FALSE)
  
  return(results)
}

# Run dataset size analysis
dataset_size_results <- analyze_dataset_size_impact(data, 
                                                   book_sizes = c(30, 60, 90, 120, 150),
                                                   n_folds = 3, optimal_params = optimal_params)

# Display results in formatted table
kable(dataset_size_results, 
      caption = "Dataset Size Impact on Predictive Accuracy",
      format = "html") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"),
                full_width = FALSE,
                position = "center") %>%
  column_spec(3:4, color = "red") %>%
  add_footnote("Note: Lower RMSE values indicate better performance")
```

